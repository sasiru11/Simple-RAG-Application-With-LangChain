{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP3BrRGJLaAs5CLxdPyxAPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasiru11/Simple-RAG-Application-With-LangChain/blob/main/SimpleRAGAplicationWithLangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple RAG Aplication using LangChain and OpenAI"
      ],
      "metadata": {
        "id": "R7JboLW_NGkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the necessory packages\n",
        "\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-chroma -qU"
      ],
      "metadata": {
        "id": "93x_Pu0CNPh4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "bqb6uRtlNggJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize OpenAI LLM\n"
      ],
      "metadata": {
        "id": "m--EGrnEOVaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#Set OpenAI API Key\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "#Initialize the chat openai model\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-3.5-turbo\",temperature=0)"
      ],
      "metadata": {
        "id": "MviyekdmOZfS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Embedding Model"
      ],
      "metadata": {
        "id": "N4PaVVSnO-Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "oYmwl4n4O9sa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an embeded Document"
      ],
      "metadata": {
        "id": "hImZtlQ9PRzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "#Define a list of documents with content and method\n",
        "\n",
        "documents = [Document(page_content = \"The T20 world cup 2024 is in full swing, bring excitement and drama to cricket fans world wide\",metadata = {\"source\":\"cricket news\"}),\n",
        "             Document(page_content = \"The fifa world cup held that date\",metadata = {\"source\":\"Sport news\"}),\n",
        "             Document(page_content = \"In 2025 AI will come forth\",metadata = {\"source\":\"AI news\"})]"
      ],
      "metadata": {
        "id": "ZRst0i3vPV1l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Document in vector Database"
      ],
      "metadata": {
        "id": "4a9B5p2DQdua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vector store using the documents and embedding models\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents,embedding = embedding_model,)"
      ],
      "metadata": {
        "id": "RovO4d4DQhtG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity Search"
      ],
      "metadata": {
        "id": "dmmWWd9LQ7XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = vectorstore.similarity_search(\"test match\")\n",
        "for result in result:\n",
        "  print(\"-----------------\")\n",
        "  print(result.page_content)\n",
        "  print(result.metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HqdPivGSgKF",
        "outputId": "05d1a20a-0382-49ed-b489-4d6157be06c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "The T20 world cup 2024 is in full swing, bring excitement and drama to cricket fans world wide\n",
            "{'source': 'cricket news'}\n",
            "-----------------\n",
            "The fifa world cup held that date\n",
            "{'source': 'Sport news'}\n",
            "-----------------\n",
            "In 2025 AI will come forth\n",
            "{'source': 'AI news'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embed Query and perform similerity search by vector"
      ],
      "metadata": {
        "id": "dXqdPSziTO7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#embed a query using the embedding model\n",
        "\n",
        "query_embedding = embedding_model.embed_query(\"machine learning\")\n",
        "\n",
        "query_embedding[:10]\n",
        "\n",
        "#peint the length of the query embedding\n",
        "len(query_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r7310xeSwXr",
        "outputId": "1b56e9f1-83b4-49a6-ac82-ee82d4a04e7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search_by_vector(query_embedding,)\n",
        "for result in results:\n",
        "  print(\"-----------------\")\n",
        "  print(result.page_content)\n",
        "  print(result.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYqPDStyUFtu",
        "outputId": "20eefdfa-8cb8-4e19-c62b-10768336116c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "In 2025 AI will come forth\n",
            "{'source': 'AI news'}\n",
            "-----------------\n",
            "The fifa world cup held that date\n",
            "{'source': 'Sport news'}\n",
            "-----------------\n",
            "The T20 world cup 2024 is in full swing, bring excitement and drama to cricket fans world wide\n",
            "{'source': 'cricket news'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Retriver"
      ],
      "metadata": {
        "id": "YC0e3FtWUQCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create retriver from the vector\n",
        "\n",
        "retriver = vectorstore.as_retriever(\n",
        "    search_type = \"similarity\",\n",
        "    search_kwargs = {\"k\":1}\n",
        ")"
      ],
      "metadata": {
        "id": "RTZDhNKqUSyM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform batch retrival using the retrival\n",
        "\n",
        "batch_result = retriver.batch([\"machine learning\",\"test match\"])\n",
        "\n",
        "for result in batch_result:\n",
        "  print(\"-----------------\")\n",
        "  for doc in result:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KtJjU16Uhaz",
        "outputId": "83b98bdb-c24e-416e-dcfc-830bc69e4d0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "In 2025 AI will come forth\n",
            "{'source': 'AI news'}\n",
            "-----------------\n",
            "The T20 world cup 2024 is in full swing, bring excitement and drama to cricket fans world wide\n",
            "{'source': 'cricket news'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create prompt template"
      ],
      "metadata": {
        "id": "gnzlr_S0U8lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "#Define a message template for the Chatbot\n",
        "\n",
        "message = \"\"\"\n",
        "              Answer the question using the provide context only\n",
        "              {question}\n",
        "              Contect{context}\n",
        "              \"\"\""
      ],
      "metadata": {
        "id": "r4ILep5eU-ur"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a chatprompt template for the message\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([(\"human\",message)])"
      ],
      "metadata": {
        "id": "yXTFOUR5Vlhy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain retriever and Prompt template with LLM"
      ],
      "metadata": {
        "id": "V2_NckZ2V3-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = {\"context\":retriver,\"question\":RunnablePassthrough()} | prompt | llm\n",
        "\n",
        "response = chain.invoke(\"tell me something\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAjuI7yOV-Fq",
        "outputId": "39fdeced-b388-4450-d532-6ad25348d95a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In 2025, AI will come forth.\n"
          ]
        }
      ]
    }
  ]
}